{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import collections\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test1_combined.csv\")\n",
    "df = pd.read_csv(\"train1_combined.csv\")\n",
    "dev = pd.read_csv(\"dev1_combined.csv\")\n",
    "train_full = pd.read_csv('train_transformed9feat.csv')\n",
    "test_full = pd.read_csv('test_transformed9feat.csv')\n",
    "with open('training_labels_combined.ob', 'rb') as f:\n",
    "    train_full_label = pickle.load(f)\n",
    "\n",
    "#test.drop(test.columns[[13,14]], axis=1, inplace=True)\n",
    "#df.drop(df.columns[[13,14]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full_label = train_full_label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             aa        ra        jc   pa  path_len      dc_A      dc_B  \\\n",
      "0      2.471649  0.531746  0.428571   96         1  0.002124  0.003186   \n",
      "1      2.976054  0.668651  0.466667  112         1  0.002124  0.003717   \n",
      "2      2.899858  0.628968  0.700000   72         1  0.002124  0.002390   \n",
      "3      2.471649  0.531746  0.600000   64         1  0.002124  0.002124   \n",
      "4      2.976054  0.668651  0.466667  112         1  0.002124  0.003717   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "32067  0.000000  0.000000  0.000000  510         3  0.002655  0.001328   \n",
      "32068  0.000000  0.000000  0.000000   30       999  0.002655  0.001593   \n",
      "32069  0.000000  0.000000  0.000000  310         3  0.002655  0.002390   \n",
      "32070  0.000000  0.000000  0.000000  140         3  0.002655  0.001062   \n",
      "32071  0.000000  0.000000  0.000000   60         4  0.002655  0.001062   \n",
      "\n",
      "         bet_cA        bet_cB  \n",
      "0      0.000004  7.627580e-04  \n",
      "1      0.000004  7.945610e-04  \n",
      "2      0.000004  9.620000e-06  \n",
      "3      0.000004  4.700000e-08  \n",
      "4      0.000004  4.391450e-04  \n",
      "...         ...           ...  \n",
      "32067  0.000371  4.349246e-03  \n",
      "32068  0.000371  0.000000e+00  \n",
      "32069  0.000371  6.463828e-03  \n",
      "32070  0.000371  3.241458e-03  \n",
      "32071  0.000371  1.780000e-05  \n",
      "\n",
      "[32072 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "train_full = train_full.iloc[:,4:]\n",
    "print(train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full = test_full.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32072, 9)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Author_A</th>\n",
       "      <th>Author_B</th>\n",
       "      <th>count</th>\n",
       "      <th>aa</th>\n",
       "      <th>ra</th>\n",
       "      <th>jc</th>\n",
       "      <th>pa</th>\n",
       "      <th>dc_A</th>\n",
       "      <th>dc_B</th>\n",
       "      <th>sh_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8763</td>\n",
       "      <td>3005</td>\n",
       "      <td>3863</td>\n",
       "      <td>1</td>\n",
       "      <td>1.213667</td>\n",
       "      <td>0.268868</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>64</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11885</td>\n",
       "      <td>629</td>\n",
       "      <td>1947</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2339</td>\n",
       "      <td>1518</td>\n",
       "      <td>915</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4059</td>\n",
       "      <td>1937</td>\n",
       "      <td>2161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11905</td>\n",
       "      <td>657</td>\n",
       "      <td>1802</td>\n",
       "      <td>4</td>\n",
       "      <td>7.113244</td>\n",
       "      <td>1.121676</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>675</td>\n",
       "      <td>0.007242</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27353</th>\n",
       "      <td>3606</td>\n",
       "      <td>183</td>\n",
       "      <td>3716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27354</th>\n",
       "      <td>8480</td>\n",
       "      <td>3084</td>\n",
       "      <td>1816</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27355</th>\n",
       "      <td>92</td>\n",
       "      <td>1017</td>\n",
       "      <td>1784</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27356</th>\n",
       "      <td>7313</td>\n",
       "      <td>2559</td>\n",
       "      <td>3808</td>\n",
       "      <td>3</td>\n",
       "      <td>0.434294</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27357</th>\n",
       "      <td>10732</td>\n",
       "      <td>3990</td>\n",
       "      <td>1703</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>220</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27358 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Author_A  Author_B  count        aa        ra        jc  \\\n",
       "0            8763      3005      3863      1  1.213667  0.268868  0.176471   \n",
       "1           11885       629      1947      1  0.000000  0.000000  0.000000   \n",
       "2            2339      1518       915      1  0.000000  0.000000  0.000000   \n",
       "3            4059      1937      2161      1  0.000000  0.000000  0.000000   \n",
       "4           11905       657      1802      4  7.113244  1.121676  0.733333   \n",
       "...           ...       ...       ...    ...       ...       ...       ...   \n",
       "27353        3606       183      3716      1  0.000000  0.000000  0.000000   \n",
       "27354        8480      3084      1816      1  0.000000  0.000000  0.000000   \n",
       "27355          92      1017      1784      1  0.000000  0.000000  0.000000   \n",
       "27356        7313      2559      3808      3  0.434294  0.100000  0.100000   \n",
       "27357       10732      3990      1703      1  0.000000  0.000000  0.000000   \n",
       "\n",
       "        pa      dc_A      dc_B  sh_path  label  \n",
       "0       64  0.004635  0.001159        1      1  \n",
       "1       14  0.000579  0.006373        5      0  \n",
       "2       21  0.000869  0.002607        4      0  \n",
       "3      256  0.008111  0.001738        6      0  \n",
       "4      675  0.007242  0.007822        1      1  \n",
       "...    ...       ...       ...      ...    ...  \n",
       "27353   36  0.001738  0.002897        4      0  \n",
       "27354   10  0.000579  0.000579        4      0  \n",
       "27355   24  0.000579  0.000579      999      0  \n",
       "27356   18  0.002607  0.000579        1      1  \n",
       "27357  220  0.011587  0.000869        3      0  \n",
       "\n",
       "[27358 rows x 12 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_shuffled = shuffle(df, random_state=785291)\n",
    "df_shuffled.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ra</th>\n",
       "      <th>jc</th>\n",
       "      <th>pa</th>\n",
       "      <th>dc_A</th>\n",
       "      <th>dc_B</th>\n",
       "      <th>sh_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8763</th>\n",
       "      <td>1.213667</td>\n",
       "      <td>0.268868</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>64</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25564</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16018</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17738</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11905</th>\n",
       "      <td>7.113244</td>\n",
       "      <td>1.121676</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>675</td>\n",
       "      <td>0.007242</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17285</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22159</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13771</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7313</th>\n",
       "      <td>0.434294</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24411</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>220</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27358 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             aa        ra        jc   pa      dc_A      dc_B  sh_path\n",
       "8763   1.213667  0.268868  0.176471   64  0.004635  0.001159        1\n",
       "25564  0.000000  0.000000  0.000000   14  0.000579  0.006373        5\n",
       "16018  0.000000  0.000000  0.000000   21  0.000869  0.002607        4\n",
       "17738  0.000000  0.000000  0.000000  256  0.008111  0.001738        6\n",
       "11905  7.113244  1.121676  0.733333  675  0.007242  0.007822        1\n",
       "...         ...       ...       ...  ...       ...       ...      ...\n",
       "17285  0.000000  0.000000  0.000000   36  0.001738  0.002897        4\n",
       "22159  0.000000  0.000000  0.000000   10  0.000579  0.000579        4\n",
       "13771  0.000000  0.000000  0.000000   24  0.000579  0.000579      999\n",
       "7313   0.434294  0.100000  0.100000   18  0.002607  0.000579        1\n",
       "24411  0.000000  0.000000  0.000000  220  0.011587  0.000869        3\n",
       "\n",
       "[27358 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled.iloc[:,4:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all = df.iloc[:,4:-1]\n",
    "y_train_all = df.label\n",
    "x_dev = dev.iloc[:,4:-1]\n",
    "y_dev = dev.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ra</th>\n",
       "      <th>jc</th>\n",
       "      <th>pa</th>\n",
       "      <th>dc_A</th>\n",
       "      <th>dc_B</th>\n",
       "      <th>sh_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.508376</td>\n",
       "      <td>0.551129</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>88</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.049436</td>\n",
       "      <td>0.707973</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>104</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.984187</td>\n",
       "      <td>0.673785</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>72</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.027478</td>\n",
       "      <td>0.426129</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>56</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.060384</td>\n",
       "      <td>0.713467</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>112</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27353</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27354</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27355</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>207</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27356</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27357</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27358 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             aa        ra        jc   pa      dc_A      dc_B  sh_path\n",
       "0      2.508376  0.551129  0.461538   88  0.002317  0.003187        1\n",
       "1      3.049436  0.707973  0.500000  104  0.002317  0.003766        1\n",
       "2      2.984187  0.673785  0.700000   72  0.002317  0.002607        1\n",
       "3      2.027478  0.426129  0.500000   56  0.002317  0.002028        1\n",
       "4      3.060384  0.713467  0.466667  112  0.002317  0.004056        1\n",
       "...         ...       ...       ...  ...       ...       ...      ...\n",
       "27353  0.000000  0.000000  0.000000   51  0.002607  0.000290        3\n",
       "27354  0.000000  0.000000  0.000000   27  0.002607  0.000290      999\n",
       "27355  0.000000  0.000000  0.000000  207  0.002607  0.002317        3\n",
       "27356  0.000000  0.000000  0.000000   27  0.002607  0.003476        3\n",
       "27357  0.000000  0.000000  0.000000  144  0.002607  0.002317        3\n",
       "\n",
       "[27358 rows x 7 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [0.2, 0.4, 0.6, 0.8]\n",
    "x_train2 = []\n",
    "y_train2 = []\n",
    "for i in range(len(splits)):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_train_all, y_train_all, train_size=splits[i], random_state=42, stratify=y_train_all)\n",
    "    x_train2.append(x_test)\n",
    "    y_train2.append(y_test)\n",
    "x_train2.insert(0,x_train_all)\n",
    "y_train2.insert(0,y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21886,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10110, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5055"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev[dev.label ==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ra</th>\n",
       "      <th>jc</th>\n",
       "      <th>pa</th>\n",
       "      <th>dc_A</th>\n",
       "      <th>dc_B</th>\n",
       "      <th>sh_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.508376</td>\n",
       "      <td>0.551129</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>88</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.049436</td>\n",
       "      <td>0.707973</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>104</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.984187</td>\n",
       "      <td>0.673785</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>72</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.027478</td>\n",
       "      <td>0.426129</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>56</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.060384</td>\n",
       "      <td>0.713467</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>112</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27353</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27354</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27355</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>207</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27356</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27357</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27358 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             aa        ra        jc   pa      dc_A      dc_B  sh_path\n",
       "0      2.508376  0.551129  0.461538   88  0.002317  0.003187        1\n",
       "1      3.049436  0.707973  0.500000  104  0.002317  0.003766        1\n",
       "2      2.984187  0.673785  0.700000   72  0.002317  0.002607        1\n",
       "3      2.027478  0.426129  0.500000   56  0.002317  0.002028        1\n",
       "4      3.060384  0.713467  0.466667  112  0.002317  0.004056        1\n",
       "...         ...       ...       ...  ...       ...       ...      ...\n",
       "27353  0.000000  0.000000  0.000000   51  0.002607  0.000290        3\n",
       "27354  0.000000  0.000000  0.000000   27  0.002607  0.000290      999\n",
       "27355  0.000000  0.000000  0.000000  207  0.002607  0.002317        3\n",
       "27356  0.000000  0.000000  0.000000   27  0.002607  0.003476        3\n",
       "27357  0.000000  0.000000  0.000000  144  0.002607  0.002317        3\n",
       "\n",
       "[27358 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,4:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ra</th>\n",
       "      <th>jc</th>\n",
       "      <th>pa</th>\n",
       "      <th>dc_A</th>\n",
       "      <th>dc_B</th>\n",
       "      <th>sh_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>432</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.242670</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>57</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>391</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>0.006663</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.006083</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1.508374</td>\n",
       "      <td>0.404053</td>\n",
       "      <td>0.05</td>\n",
       "      <td>236</td>\n",
       "      <td>0.017092</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aa        ra    jc   pa      dc_A      dc_B  sh_path\n",
       "0     0.000000  0.000000  0.00   40  0.002317  0.001448        3\n",
       "1     0.000000  0.000000  0.00   24  0.002317  0.000869        6\n",
       "2     0.000000  0.000000  0.00  432  0.004635  0.007822        4\n",
       "3     1.242670  0.400000  0.10   57  0.005504  0.000869        1\n",
       "4     0.000000  0.000000  0.00  391  0.004925  0.006663        4\n",
       "...        ...       ...   ...  ...       ...       ...      ...\n",
       "1995  0.000000  0.000000  0.00    2  0.000290  0.000579        1\n",
       "1996  0.000000  0.000000  0.00    2  0.000579  0.000290      999\n",
       "1997  0.000000  0.000000  0.00   42  0.000579  0.006083        3\n",
       "1998  1.508374  0.404053  0.05  236  0.017092  0.001159        1\n",
       "1999  0.000000  0.000000  0.00   15  0.004345  0.000290        5\n",
       "\n",
       "[2000 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [True if i < df.shape[0]/2 else False for i in range(df.shape[0])]\n",
    "x = df.iloc[:,4:13]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 13679, False: 13679})"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1353: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 1245, 1.0: 755})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(n_jobs = 4, penalty = 'l1', solver = 'liblinear').fit(train_full, train_full_label)\n",
    "collections.Counter(LR.predict(test_full))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.54274468e-04, 3.57277437e-09, 6.01940118e-04, ...,\n",
       "       8.14453865e-04, 9.99999127e-01, 3.59846951e-09])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = LR.predict_proba(test_full)\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': results[:,1]})\n",
    "output.to_csv('logReg_7feat_hyper_full.csv', header = True, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression development on dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ra</th>\n",
       "      <th>jc</th>\n",
       "      <th>pa</th>\n",
       "      <th>dc_A</th>\n",
       "      <th>dc_B</th>\n",
       "      <th>sh_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.508376</td>\n",
       "      <td>0.551129</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>88</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.049436</td>\n",
       "      <td>0.707973</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>104</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.984187</td>\n",
       "      <td>0.673785</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>72</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.027478</td>\n",
       "      <td>0.426129</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>56</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.060384</td>\n",
       "      <td>0.713467</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>112</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27353</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27354</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27355</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>207</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27356</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27357</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27358 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             aa        ra        jc   pa      dc_A      dc_B  sh_path\n",
       "0      2.508376  0.551129  0.461538   88  0.002317  0.003187        1\n",
       "1      3.049436  0.707973  0.500000  104  0.002317  0.003766        1\n",
       "2      2.984187  0.673785  0.700000   72  0.002317  0.002607        1\n",
       "3      2.027478  0.426129  0.500000   56  0.002317  0.002028        1\n",
       "4      3.060384  0.713467  0.466667  112  0.002317  0.004056        1\n",
       "...         ...       ...       ...  ...       ...       ...      ...\n",
       "27353  0.000000  0.000000  0.000000   51  0.002607  0.000290        3\n",
       "27354  0.000000  0.000000  0.000000   27  0.002607  0.000290      999\n",
       "27355  0.000000  0.000000  0.000000  207  0.002607  0.002317        3\n",
       "27356  0.000000  0.000000  0.000000   27  0.002607  0.003476        3\n",
       "27357  0.000000  0.000000  0.000000  144  0.002607  0.002317        3\n",
       "\n",
       "[27358 rows x 7 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#normal = StandardScaler()\n",
    "#x_train = normal.fit_transform(x_train)\n",
    "#x_test = normal.transform(x_test)\n",
    "#l1', 'C': 1.0, 'max_iter': 200, 'solver': 'liblinear'\n",
    "auc_train = []\n",
    "auc_dev = []\n",
    "for i in range(len(x_train2)):\n",
    "    LR = LogisticRegression(penalty = 'l1', solver = 'liblinear').fit(x_train2[i], y_train2[i])\n",
    "    probs_train = LR.predict_proba(x_train_all)\n",
    "    probs_dev = LR.predict_proba(dev.iloc[:,4:-1])\n",
    "    auc_train.append(metrics.roc_auc_score(y_train_all, probs_train[:, 1]))\n",
    "    auc_dev.append(metrics.roc_auc_score(dev.label, probs_dev[:, 1]))\n",
    "\n",
    "#print(metrics.classification_report(dev.label, LRT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 0.9999999999999999]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on same train set which is full train set\n",
    "auc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8615730231547929,\n",
       " 0.8660643505025334,\n",
       " 0.8651347932387653,\n",
       " 0.8584328078573867,\n",
       " 0.852945884097871]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on same dev set which is full dev set\n",
    "auc_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = LR.predict_proba(dev.iloc[:,4:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8607886933151749"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(dev.label, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1134, 1: 866})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(LR.predict(test.iloc[:,4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.43407076e-03, 1.20590556e-08, 1.50067007e-04, ...,\n",
       "       5.45441957e-03, 9.99999646e-01, 9.01589244e-07])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = LR.predict_proba(test.iloc[:,4:])\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': results[:,1]})\n",
    "output.to_csv('logReg_7feat_hypertuned.csv', header = True, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handmade gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "from sklearn.metrics import accuracy_score\n",
    "LR = LogisticRegression\n",
    "LR_param = {'penalty':['l1', 'l2', 'elasticnet'],\n",
    "            'C':[1.0,0.5,0.1,0.01], 'max_iter':[200],\n",
    "           'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "models = [('Logistic Regression',LR,LR_param)]\n",
    "\n",
    "result = []\n",
    "best = {}\n",
    "for name, m, params in models:\n",
    "    keys, values = zip(*params.items())\n",
    "    permutations = [dict(zip(keys, v)) for v in it.product(*values)]\n",
    "    \n",
    "    for p in permutations:\n",
    "        try:\n",
    "            mod = m(**p)\n",
    "            mod.fit(x_train, y_train);\n",
    "            y_pred = mod.predict(x_dev)\n",
    "            Acc_scored = accuracy_score(y_dev, y_pred)\n",
    "            cnt = collections.Counter(mod.predict(test.iloc[:,4:]))\n",
    "            best[str(p)] = (Acc_scored, cnt)\n",
    "            #print('Model: ',name, ' HyperParams: ',p,' Accuracy: ',Acc_scored)\n",
    "        except:\n",
    "            pass#print(p)\n",
    "\n",
    "    #best_params = max(best, key = lambda k:best[k][0])\n",
    "    #result.append((name, best_params, best[best_params][0], best[best_params][1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 1.0, 'max_iter': 200, 'solver': 'liblinear'} (0.7889218595450049, Counter({0: 1131, 1: 869}))\n",
      "{'penalty': 'l1', 'C': 1.0, 'max_iter': 200, 'solver': 'saga'} (0.7008902077151336, Counter({0: 1070, 1: 930}))\n",
      "{'penalty': 'l1', 'C': 0.5, 'max_iter': 200, 'solver': 'liblinear'} (0.7884272997032641, Counter({0: 1147, 1: 853}))\n",
      "{'penalty': 'l1', 'C': 0.5, 'max_iter': 200, 'solver': 'saga'} (0.7008902077151336, Counter({0: 1070, 1: 930}))\n",
      "{'penalty': 'l1', 'C': 0.1, 'max_iter': 200, 'solver': 'liblinear'} (0.786053412462908, Counter({0: 1152, 1: 848}))\n",
      "{'penalty': 'l1', 'C': 0.1, 'max_iter': 200, 'solver': 'saga'} (0.7008902077151336, Counter({0: 1070, 1: 930}))\n",
      "{'penalty': 'l1', 'C': 0.01, 'max_iter': 200, 'solver': 'liblinear'} (0.7831849653808111, Counter({0: 1160, 1: 840}))\n",
      "{'penalty': 'l1', 'C': 0.01, 'max_iter': 200, 'solver': 'saga'} (0.7008902077151336, Counter({0: 1070, 1: 930}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'newton-cg'} (0.786646884272997, Counter({0: 1134, 1: 866}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'lbfgs'} (0.786646884272997, Counter({0: 1134, 1: 866}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'liblinear'} (0.7899109792284866, Counter({0: 1139, 1: 861}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'sag'} (0.7135509396636993, Counter({0: 1241, 1: 759}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'saga'} (0.7008902077151336, Counter({0: 1070, 1: 930}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'newton-cg'} (0.7861523244312562, Counter({0: 1132, 1: 868}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'lbfgs'} (0.7861523244312562, Counter({0: 1132, 1: 868}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'liblinear'} (0.790108803165183, Counter({0: 1138, 1: 862}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'sag'} (0.7135509396636993, Counter({0: 1241, 1: 759}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'saga'} (0.7008902077151336, Counter({0: 1070, 1: 930}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'newton-cg'} (0.7824925816023739, Counter({0: 1129, 1: 871}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'lbfgs'} (0.7824925816023739, Counter({0: 1129, 1: 871}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'liblinear'} (0.7881305637982196, Counter({0: 1137, 1: 863}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'sag'} (0.7135509396636993, Counter({0: 1241, 1: 759}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'saga'} (0.7008902077151336, Counter({0: 1070, 1: 930}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'newton-cg'} (0.7742828882294758, Counter({0: 1105, 1: 895}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'lbfgs'} (0.7742828882294758, Counter({0: 1105, 1: 895}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'liblinear'} (0.7795252225519288, Counter({0: 1161, 1: 839}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'sag'} (0.7135509396636993, Counter({0: 1241, 1: 759}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'saga'} (0.7008902077151336, Counter({0: 1070, 1: 930}))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(k,v) for k,v in best.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-59b485257a07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "train_data = lgbm.Dataset(x_train, pd.Series(y_train))\n",
    "test_data = lgbm.Dataset(x_dev, pd.Series(y_dev))\n",
    "\n",
    "# define parameters\n",
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'num_threads' : 2,\n",
    "    'seed' : 76\n",
    "}\n",
    "\n",
    "# train lightGBM model\n",
    "model = lgbm.train(parameters,\n",
    "                   train_data,\n",
    "                   valid_sets=test_data,\n",
    "                   num_boost_round=1000,\n",
    "                   early_stopping_rounds=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49348902, 0.49348902, 0.49348902, ..., 0.49348902, 0.49348902,\n",
       "       0.49348902])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neg': 1439, 'pos': 561})"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict= model.predict(test.iloc[:,4:])\n",
    "collections.Counter([\"pos\" if i>0.5 else \"neg\" for i in predict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM on full training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisation of data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# define min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "train_full = scaler.fit_transform(train_full)\n",
    "test_full = scaler.fit_transform(test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=SVC())"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = SVC(kernel='rbf', C=1.0)\n",
    "clf = CalibratedClassifierCV(SVM) \n",
    "clf.fit(train_full, train_full_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 1251, 1.0: 749})"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(clf.predict(test_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06479071, 0.06399281, 0.11928247, ..., 0.11601861, 0.99999939,\n",
       "       0.0642454 ])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = clf.predict_proba(test_full)\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': results[:,1]})\n",
    "output.to_csv('svm_9feat_hyper_full.csv', header = True, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM) - development and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# define min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_dev = scaler.fit_transform(x_dev)\n",
    "test = test.iloc[:,4:]\n",
    "test = scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1354199 , 0.1771918 , 0.49846154, ..., 0.0619469 , 0.08849559,\n",
       "        0.001001  ],\n",
       "       [0.16463012, 0.22761792, 0.54      , ..., 0.0619469 , 0.1061947 ,\n",
       "        0.001001  ],\n",
       "       [0.16110755, 0.21662624, 0.756     , ..., 0.0619469 , 0.07079646,\n",
       "        0.001001  ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.07079646, 0.0619469 ,\n",
       "        0.003003  ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.07079646, 0.09734515,\n",
       "        0.003003  ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.07079646, 0.0619469 ,\n",
       "        0.003003  ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: linear c: 0.001\n",
      "0.804210303868133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78      5055\n",
      "           1       0.84      0.64      0.73      5055\n",
      "\n",
      "    accuracy                           0.76     10110\n",
      "   macro avg       0.77      0.76      0.76     10110\n",
      "weighted avg       0.77      0.76      0.76     10110\n",
      "\n",
      "kernel: linear c: 0.01\n",
      "0.8137276897744984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.91      0.80      5055\n",
      "           1       0.87      0.64      0.74      5055\n",
      "\n",
      "    accuracy                           0.77     10110\n",
      "   macro avg       0.79      0.77      0.77     10110\n",
      "weighted avg       0.79      0.77      0.77     10110\n",
      "\n",
      "kernel: linear c: 0.1\n",
      "0.81821279476696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.99      0.82      5055\n",
      "           1       0.98      0.58      0.73      5055\n",
      "\n",
      "    accuracy                           0.79     10110\n",
      "   macro avg       0.84      0.79      0.78     10110\n",
      "weighted avg       0.84      0.79      0.78     10110\n",
      "\n",
      "kernel: linear c: 0.5\n",
      "0.8219907036446761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.99      0.82      5055\n",
      "           1       0.98      0.57      0.72      5055\n",
      "\n",
      "    accuracy                           0.78     10110\n",
      "   macro avg       0.84      0.78      0.77     10110\n",
      "weighted avg       0.84      0.78      0.77     10110\n",
      "\n",
      "kernel: linear c: 0.8\n",
      "0.8370282187725329\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.99      0.81      5055\n",
      "           1       0.98      0.54      0.70      5055\n",
      "\n",
      "    accuracy                           0.77     10110\n",
      "   macro avg       0.83      0.77      0.75     10110\n",
      "weighted avg       0.83      0.77      0.75     10110\n",
      "\n",
      "kernel: linear c: 1.0\n",
      "0.8471711274888198\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.99      0.81      5055\n",
      "           1       0.98      0.56      0.71      5055\n",
      "\n",
      "    accuracy                           0.77     10110\n",
      "   macro avg       0.84      0.77      0.76     10110\n",
      "weighted avg       0.84      0.77      0.76     10110\n",
      "\n",
      "kernel: poly c: 0.001\n",
      "0.7862780629690613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.96      0.73      5055\n",
      "           1       0.89      0.32      0.47      5055\n",
      "\n",
      "    accuracy                           0.64     10110\n",
      "   macro avg       0.74      0.64      0.60     10110\n",
      "weighted avg       0.74      0.64      0.60     10110\n",
      "\n",
      "kernel: poly c: 0.01\n",
      "0.8020322447146667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.99      0.73      5055\n",
      "           1       0.97      0.26      0.41      5055\n",
      "\n",
      "    accuracy                           0.62     10110\n",
      "   macro avg       0.77      0.62      0.57     10110\n",
      "weighted avg       0.77      0.62      0.57     10110\n",
      "\n",
      "kernel: poly c: 0.1\n",
      "0.8244347978370467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.72      5055\n",
      "           1       0.99      0.24      0.39      5055\n",
      "\n",
      "    accuracy                           0.62     10110\n",
      "   macro avg       0.78      0.62      0.56     10110\n",
      "weighted avg       0.78      0.62      0.56     10110\n",
      "\n",
      "kernel: poly c: 0.5\n",
      "0.8580110965335808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.72      5055\n",
      "           1       0.99      0.21      0.35      5055\n",
      "\n",
      "    accuracy                           0.60     10110\n",
      "   macro avg       0.78      0.60      0.53     10110\n",
      "weighted avg       0.78      0.60      0.53     10110\n",
      "\n",
      "kernel: poly c: 0.8\n",
      "0.8653828264951018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.72      5055\n",
      "           1       0.99      0.23      0.38      5055\n",
      "\n",
      "    accuracy                           0.62     10110\n",
      "   macro avg       0.78      0.62      0.55     10110\n",
      "weighted avg       0.78      0.62      0.55     10110\n",
      "\n",
      "kernel: poly c: 1.0\n",
      "0.8671658247898244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73      5055\n",
      "           1       0.99      0.25      0.40      5055\n",
      "\n",
      "    accuracy                           0.62     10110\n",
      "   macro avg       0.78      0.62      0.56     10110\n",
      "weighted avg       0.78      0.62      0.56     10110\n",
      "\n",
      "kernel: rbf c: 0.001\n",
      "0.7986423133855972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78      5055\n",
      "           1       0.83      0.64      0.72      5055\n",
      "\n",
      "    accuracy                           0.75     10110\n",
      "   macro avg       0.77      0.75      0.75     10110\n",
      "weighted avg       0.77      0.75      0.75     10110\n",
      "\n",
      "kernel: rbf c: 0.01\n",
      "0.8345057776916822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.81      5055\n",
      "           1       0.88      0.65      0.75      5055\n",
      "\n",
      "    accuracy                           0.78     10110\n",
      "   macro avg       0.80      0.78      0.78     10110\n",
      "weighted avg       0.80      0.78      0.78     10110\n",
      "\n",
      "kernel: rbf c: 0.1\n",
      "0.8742996181469709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.95      0.83      5055\n",
      "           1       0.93      0.66      0.77      5055\n",
      "\n",
      "    accuracy                           0.81     10110\n",
      "   macro avg       0.83      0.81      0.80     10110\n",
      "weighted avg       0.83      0.81      0.80     10110\n",
      "\n",
      "kernel: rbf c: 0.5\n",
      "0.9002632760700543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84      5055\n",
      "           1       0.95      0.65      0.78      5055\n",
      "\n",
      "    accuracy                           0.81     10110\n",
      "   macro avg       0.85      0.81      0.81     10110\n",
      "weighted avg       0.85      0.81      0.81     10110\n",
      "\n",
      "kernel: rbf c: 0.8\n",
      "0.9032599467186371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84      5055\n",
      "           1       0.96      0.65      0.78      5055\n",
      "\n",
      "    accuracy                           0.81     10110\n",
      "   macro avg       0.85      0.81      0.81     10110\n",
      "weighted avg       0.85      0.81      0.81     10110\n",
      "\n",
      "kernel: rbf c: 1.0\n",
      "0.90392393855522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84      5055\n",
      "           1       0.96      0.65      0.78      5055\n",
      "\n",
      "    accuracy                           0.81     10110\n",
      "   macro avg       0.85      0.81      0.81     10110\n",
      "weighted avg       0.85      0.81      0.81     10110\n",
      "\n",
      "kernel: sigmoid c: 0.001\n",
      "0.8109452794727826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79      5055\n",
      "           1       0.83      0.66      0.74      5055\n",
      "\n",
      "    accuracy                           0.76     10110\n",
      "   macro avg       0.78      0.76      0.76     10110\n",
      "weighted avg       0.78      0.76      0.76     10110\n",
      "\n",
      "kernel: sigmoid c: 0.01\n",
      "0.7883684221339743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74      5055\n",
      "           1       0.74      0.72      0.73      5055\n",
      "\n",
      "    accuracy                           0.73     10110\n",
      "   macro avg       0.73      0.73      0.73     10110\n",
      "weighted avg       0.73      0.73      0.73     10110\n",
      "\n",
      "kernel: sigmoid c: 0.1\n",
      "0.7833264750455181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73      5055\n",
      "           1       0.73      0.73      0.73      5055\n",
      "\n",
      "    accuracy                           0.73     10110\n",
      "   macro avg       0.73      0.73      0.73     10110\n",
      "weighted avg       0.73      0.73      0.73     10110\n",
      "\n",
      "kernel: sigmoid c: 0.5\n",
      "0.782597676791691\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73      5055\n",
      "           1       0.73      0.73      0.73      5055\n",
      "\n",
      "    accuracy                           0.73     10110\n",
      "   macro avg       0.73      0.73      0.73     10110\n",
      "weighted avg       0.73      0.73      0.73     10110\n",
      "\n",
      "kernel: sigmoid c: 0.8\n",
      "0.7825355315075221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73      5055\n",
      "           1       0.73      0.73      0.73      5055\n",
      "\n",
      "    accuracy                           0.73     10110\n",
      "   macro avg       0.73      0.73      0.73     10110\n",
      "weighted avg       0.73      0.73      0.73     10110\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: sigmoid c: 1.0\n",
      "0.7825145946517096\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73      5055\n",
      "           1       0.73      0.73      0.73      5055\n",
      "\n",
      "    accuracy                           0.73     10110\n",
      "   macro avg       0.73      0.73      0.73     10110\n",
      "weighted avg       0.73      0.73      0.73     10110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = [0.001, 0.01, 0.1, 0.5, 0.8, 1.0]\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid'] # cannot use precomputed as square matrix as input required\n",
    "for kernel in kernels:\n",
    "    for c in C:\n",
    "        SVM = SVC(kernel=kernel, C=c)\n",
    "        #SVM_predict = SVM.predict(x_test)\n",
    "        clf = CalibratedClassifierCV(SVM) \n",
    "        clf.fit(x_train, y_train)\n",
    "        clf_predict = clf.predict(x_dev)\n",
    "\n",
    "        probs = clf.predict_proba(x_dev)\n",
    "        print(\"kernel:\", kernel, 'c:', c)\n",
    "        print(metrics.roc_auc_score(y_dev, probs[:, 1]))\n",
    "        print(metrics.classification_report(y_dev, clf_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7234561074471613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.78      0.70      5055\n",
      "           1       0.71      0.55      0.62      5055\n",
      "\n",
      "    accuracy                           0.66     10110\n",
      "   macro avg       0.67      0.66      0.66     10110\n",
      "weighted avg       0.67      0.66      0.66     10110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM = SVC(kernel='rbf', C=1.0)\n",
    "#SVM_predict = SVM.predict(x_test)\n",
    "clf = CalibratedClassifierCV(SVM) \n",
    "clf.fit(x_train, y_train)\n",
    "clf_predict = clf.predict(x_dev)\n",
    "\n",
    "probs = clf.predict_proba(x_dev)\n",
    "#print(\"kernel:\", kernel, 'c:', c)\n",
    "print(metrics.roc_auc_score(y_dev, probs[:, 1]))\n",
    "print(metrics.classification_report(y_dev, clf_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.34791090e-06, 9.99997652e-01],\n",
       "       [3.46543691e-07, 9.99999653e-01],\n",
       "       [4.10257686e-09, 9.99999996e-01],\n",
       "       ...,\n",
       "       [8.67132316e-01, 1.32867684e-01],\n",
       "       [8.66075798e-01, 1.33924202e-01],\n",
       "       [8.65616779e-01, 1.34383221e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90392393855522"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_dev, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1385, 1: 615})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(clf.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-57cc08dfb0e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "collections.Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06129185, 0.05327719, 0.19009618, ..., 0.06437202, 0.99999999,\n",
       "       0.05693839])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = clf.predict_proba(test)\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': results[:,1]})\n",
    "output.to_csv('svm_7feat_hypertuned.csv', header = True, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF on full training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(max_depth=8, random_state=0, oob_score=True, bootstrap=True).fit(train_full, train_full_label) # max_depth 6 is optimal depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 1215, 1.0: 785})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(rfc.predict(test_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00122951, 0.00122951, 0.00322951, ..., 0.98322951, 0.71      ,\n",
       "       0.00122951])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = rfc.predict_proba(test.iloc[:,4:])\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': results[:,1]})\n",
    "output.to_csv('randomForest_7feat_full.csv', header = True, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier - dev and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(max_depth=8, random_state=0, oob_score=True, bootstrap=True).fit(x_train, y_train) # max_depth 6 is optimal depth.\n",
    "rfc_pred = rfc.predict(x_train)\n",
    "\n",
    "#print(metrics.classification_report(x_train, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Score: ', rfc.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(rfc.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = rfc.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       ...,\n",
       "       [0.99679233, 0.00320767],\n",
       "       [0.9985441 , 0.0014559 ],\n",
       "       [0.99679233, 0.00320767]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_train, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1065, 1: 935})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(rfc.predict(test.iloc[:,4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10305407, 0.06810847, 0.63921827, ..., 0.10767577, 1.        ,\n",
       "       0.29842463])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = rfc.predict_proba(test.iloc[:,4:])\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': results[:,1]})\n",
    "output.to_csv('randomForest_6feat.csv', header = True, index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
