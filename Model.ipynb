{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test1.csv\")\n",
    "df = pd.read_csv(\"train1.csv\")\n",
    "dev = pd.read_csv(\"dev1.csv\")\n",
    "#test.drop(test.columns[[13,14]], axis=1, inplace=True)\n",
    "#df.drop(df.columns[[13,14]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.iloc[:,4:-1]\n",
    "y_train = df.label\n",
    "x_dev = dev.iloc[:,4:-1]\n",
    "y_dev = dev.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28846, 9)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22036, 9)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16036"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev[dev.label ==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ra</th>\n",
       "      <th>jc</th>\n",
       "      <th>pa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.471649</td>\n",
       "      <td>0.531746</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.976054</td>\n",
       "      <td>0.668651</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.899858</td>\n",
       "      <td>0.628968</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.471649</td>\n",
       "      <td>0.531746</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.976054</td>\n",
       "      <td>0.668651</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32067</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32068</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32069</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32070</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32071</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32072 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             aa        ra        jc   pa\n",
       "0      2.471649  0.531746  0.428571   96\n",
       "1      2.976054  0.668651  0.466667  112\n",
       "2      2.899858  0.628968  0.700000   72\n",
       "3      2.471649  0.531746  0.600000   64\n",
       "4      2.976054  0.668651  0.466667  112\n",
       "...         ...       ...       ...  ...\n",
       "32067  0.000000  0.000000  0.000000   50\n",
       "32068  0.000000  0.000000  0.000000   70\n",
       "32069  0.000000  0.000000  0.000000   20\n",
       "32070  0.000000  0.000000  0.000000   50\n",
       "32071  0.000000  0.000000  0.000000   60\n",
       "\n",
       "[32072 rows x 4 columns]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,4:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ra</th>\n",
       "      <th>jc</th>\n",
       "      <th>pa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.242670</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1.766048</td>\n",
       "      <td>0.424368</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aa        ra        jc   pa\n",
       "0     0.000000  0.000000  0.000000   56\n",
       "1     0.000000  0.000000  0.000000   24\n",
       "2     0.000000  0.000000  0.000000  496\n",
       "3     1.242670  0.400000  0.080000   72\n",
       "4     0.000000  0.000000  0.000000  391\n",
       "...        ...       ...       ...  ...\n",
       "1995  0.000000  0.000000  0.000000    2\n",
       "1996  0.000000  0.000000  0.000000    2\n",
       "1997  0.000000  0.000000  0.000000  116\n",
       "1998  1.766048  0.424368  0.053333  370\n",
       "1999  0.000000  0.000000  0.000000   15\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [True if i < df.shape[0]/2 else False for i in range(df.shape[0])]\n",
    "x = df.iloc[:,4:13]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 16036, False: 16036})"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82      6000\n",
      "           1       0.95      0.60      0.73      6000\n",
      "\n",
      "    accuracy                           0.78     12000\n",
      "   macro avg       0.83      0.78      0.77     12000\n",
      "weighted avg       0.83      0.78      0.77     12000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#normal = StandardScaler()\n",
    "#x_train = normal.fit_transform(x_train)\n",
    "#x_test = normal.transform(x_test)\n",
    "#l1', 'C': 1.0, 'max_iter': 200, 'solver': 'liblinear'\n",
    "LR = LogisticRegression(n_jobs = 4, penalty = 'l1', solver = 'liblinear').fit(df.iloc[:,4:-1], df.label)\n",
    "LRT = LR.predict(dev.iloc[:,4:-1])\n",
    "\n",
    "print(metrics.classification_report(dev.label, LRT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = LR.predict_proba(dev.iloc[:,4:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8232246805555558"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(dev.label, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1439, 1: 561})"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(LR.predict(test.iloc[:,4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07216161, 0.07062026, 0.07105751, ..., 0.07527991, 1.        ,\n",
       "       0.07029395])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = LR.predict_proba(test.iloc[:,4:])\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': results[:,1]})\n",
    "output.to_csv('logReg.csv', header = True, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handmade gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "from sklearn.metrics import accuracy_score\n",
    "LR = LogisticRegression\n",
    "LR_param = {'penalty':['l1', 'l2', 'elasticnet'],\n",
    "            'C':[1.0,0.5,0.1,0.01], 'max_iter':[200],\n",
    "           'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "models = [('Logistic Regression',LR,LR_param)]\n",
    "\n",
    "result = []\n",
    "best = {}\n",
    "for name, m, params in models:\n",
    "    keys, values = zip(*params.items())\n",
    "    permutations = [dict(zip(keys, v)) for v in it.product(*values)]\n",
    "    \n",
    "    for p in permutations:\n",
    "        try:\n",
    "            mod = m(**p)\n",
    "            mod.fit(x_train, y_train);\n",
    "            y_pred = mod.predict(x_dev)\n",
    "            Acc_scored = accuracy_score(y_dev, y_pred)\n",
    "            cnt = collections.Counter(mod.predict(test.iloc[:,4:]))\n",
    "            best[str(p)] = (Acc_scored, cnt)\n",
    "            #print('Model: ',name, ' HyperParams: ',p,' Accuracy: ',Acc_scored)\n",
    "        except:\n",
    "            pass#print(p)\n",
    "\n",
    "    #best_params = max(best, key = lambda k:best[k][0])\n",
    "    #result.append((name, best_params, best[best_params][0], best[best_params][1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 1.0, 'max_iter': 200, 'solver': 'liblinear'} (0.7816666666666666, Counter({0: 1439, 1: 561}))\n",
      "{'penalty': 'l1', 'C': 1.0, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l1', 'C': 0.5, 'max_iter': 200, 'solver': 'liblinear'} (0.7816666666666666, Counter({0: 1439, 1: 561}))\n",
      "{'penalty': 'l1', 'C': 0.5, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l1', 'C': 0.1, 'max_iter': 200, 'solver': 'liblinear'} (0.7815833333333333, Counter({0: 1439, 1: 561}))\n",
      "{'penalty': 'l1', 'C': 0.1, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l1', 'C': 0.01, 'max_iter': 200, 'solver': 'liblinear'} (0.7808333333333334, Counter({0: 1440, 1: 560}))\n",
      "{'penalty': 'l1', 'C': 0.01, 'max_iter': 200, 'solver': 'saga'} (0.51925, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'newton-cg'} (0.7818333333333334, Counter({0: 1439, 1: 561}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'lbfgs'} (0.7818333333333334, Counter({0: 1439, 1: 561}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'liblinear'} (0.7783333333333333, Counter({0: 1448, 1: 552}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'sag'} (0.566, Counter({1: 1622, 0: 378}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'newton-cg'} (0.7818333333333334, Counter({0: 1438, 1: 562}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'lbfgs'} (0.7818333333333334, Counter({0: 1438, 1: 562}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'liblinear'} (0.7779166666666667, Counter({0: 1448, 1: 552}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'sag'} (0.566, Counter({1: 1622, 0: 378}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'newton-cg'} (0.7811666666666667, Counter({0: 1440, 1: 560}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'lbfgs'} (0.7811666666666667, Counter({0: 1440, 1: 560}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'liblinear'} (0.7754166666666666, Counter({0: 1460, 1: 540}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'sag'} (0.566, Counter({1: 1622, 0: 378}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'newton-cg'} (0.7589166666666667, Counter({0: 1527, 1: 473}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'lbfgs'} (0.759, Counter({0: 1527, 1: 473}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'liblinear'} (0.75775, Counter({0: 1529, 1: 471}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'sag'} (0.566, Counter({1: 1622, 0: 378}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(k,v) for k,v in best.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12810, number of negative: 12810\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1018\n",
      "[LightGBM] [Info] Number of data points in the train set: 25620, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's auc: 0.78175\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's auc: 0.78175\n",
      "[3]\tvalid_0's auc: 0.822314\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's auc: 0.822314\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's auc: 0.82227\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's auc: 0.822207\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's auc: 0.822314\n",
      "[8]\tvalid_0's auc: 0.824169\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's auc: 0.824169\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's auc: 0.824169\n",
      "[11]\tvalid_0's auc: 0.824643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's auc: 0.824643\n",
      "[13]\tvalid_0's auc: 0.824468\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's auc: 0.824468\n",
      "[15]\tvalid_0's auc: 0.824476\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's auc: 0.824476\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's auc: 0.824476\n",
      "[18]\tvalid_0's auc: 0.825407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's auc: 0.825407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's auc: 0.825407\n",
      "[21]\tvalid_0's auc: 0.825347\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's auc: 0.825347\n",
      "[23]\tvalid_0's auc: 0.824467\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's auc: 0.824467\n",
      "[25]\tvalid_0's auc: 0.822773\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's auc: 0.822773\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's auc: 0.822773\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's auc: 0.822773\n",
      "[29]\tvalid_0's auc: 0.823589\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's auc: 0.823589\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's auc: 0.823589\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's auc: 0.823589\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's auc: 0.823589\n",
      "[34]\tvalid_0's auc: 0.824014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's auc: 0.824014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's auc: 0.824014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's auc: 0.824014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's auc: 0.824014\n",
      "[39]\tvalid_0's auc: 0.824025\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's auc: 0.824025\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's auc: 0.824025\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's auc: 0.824025\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's auc: 0.824025\n",
      "[44]\tvalid_0's auc: 0.822894\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's auc: 0.822894\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's auc: 0.822894\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's auc: 0.822894\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's auc: 0.822684\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's auc: 0.822511\n",
      "[50]\tvalid_0's auc: 0.821173\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's auc: 0.821173\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[52]\tvalid_0's auc: 0.824713\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\tvalid_0's auc: 0.824651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\tvalid_0's auc: 0.823919\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's auc: 0.823919\n",
      "[56]\tvalid_0's auc: 0.822104\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[57]\tvalid_0's auc: 0.822059\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[58]\tvalid_0's auc: 0.822057\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.825407\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "train_data = lgbm.Dataset(x_train, pd.Series(y_train))\n",
    "test_data = lgbm.Dataset(x_dev, pd.Series(y_dev))\n",
    "\n",
    "# define parameters\n",
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'num_threads' : 2,\n",
    "    'seed' : 76\n",
    "}\n",
    "\n",
    "# train lightGBM model\n",
    "model = lgbm.train(parameters,\n",
    "                   train_data,\n",
    "                   valid_sets=test_data,\n",
    "                   num_boost_round=1000,\n",
    "                   early_stopping_rounds=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49348902, 0.49348902, 0.49348902, ..., 0.49348902, 0.49348902,\n",
       "       0.49348902])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neg': 1439, 'pos': 561})"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict= model.predict(test.iloc[:,4:])\n",
    "collections.Counter([\"pos\" if i>0.5 else \"neg\" for i in predict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.99      0.78      6000\n",
      "           1       0.99      0.45      0.62      6000\n",
      "\n",
      "    accuracy                           0.72     12000\n",
      "   macro avg       0.81      0.72      0.70     12000\n",
      "weighted avg       0.81      0.72      0.70     12000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "SVM = LinearSVC(max_iter=10000)\n",
    "#SVM_predict = SVM.predict(x_test)\n",
    "clf = CalibratedClassifierCV(SVM) \n",
    "clf.fit(x_train, y_train)\n",
    "clf_predict = clf.predict(x_dev)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_dev, clf_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00746483, 0.99253517],\n",
       "       [0.00731817, 0.99268183],\n",
       "       [0.00780515, 0.99219485],\n",
       "       ...,\n",
       "       [0.82285244, 0.17714756],\n",
       "       [0.82191714, 0.17808286],\n",
       "       [0.82177594, 0.17822406]])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7539118888888888"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_dev, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neg': 1465, 'pos': 535})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(clf.predict(test.iloc[:,4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neg': 4029, 'pos': 3989})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32588784, 0.11201567, 0.32562297, ..., 0.32601893, 0.65587601,\n",
       "       0.11203549])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = clf.predict_proba(test.iloc[:,4:])\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': predict})\n",
    "output.to_csv('lightGBM.csv', header = True, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
