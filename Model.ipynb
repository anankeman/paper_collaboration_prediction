{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test_transformed_allFeatures.csv\")\n",
    "df = pd.read_csv(\"train_transformed_allFeat.csv\")\n",
    "#test.drop(test.columns[[13,14]], axis=1, inplace=True)\n",
    "#df.drop(df.columns[[13,14]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ra</th>\n",
       "      <th>jc</th>\n",
       "      <th>pa</th>\n",
       "      <th>path_len</th>\n",
       "      <th>dc_A</th>\n",
       "      <th>dc_B</th>\n",
       "      <th>cc_A</th>\n",
       "      <th>cc_B</th>\n",
       "      <th>hits_A</th>\n",
       "      <th>hits_B</th>\n",
       "      <th>bet_cA</th>\n",
       "      <th>bet_cB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.471649</td>\n",
       "      <td>0.531746</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.187879</td>\n",
       "      <td>0.223134</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>5.710000e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>7.627580e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.976054</td>\n",
       "      <td>0.668651</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.187879</td>\n",
       "      <td>0.209683</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.070000e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>7.945610e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.899858</td>\n",
       "      <td>0.628968</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.187879</td>\n",
       "      <td>0.187891</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.200000e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>9.620000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.471649</td>\n",
       "      <td>0.531746</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.187879</td>\n",
       "      <td>0.181356</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.090000e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.700000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.976054</td>\n",
       "      <td>0.668651</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.187879</td>\n",
       "      <td>0.208769</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.830000e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.391450e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32067</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>510</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.246668</td>\n",
       "      <td>0.225652</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>4.054780e-04</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>4.349246e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32068</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>999</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.246668</td>\n",
       "      <td>0.173938</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>5.740000e-07</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32069</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>310</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.246668</td>\n",
       "      <td>0.224344</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>3.290000e-05</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>6.463828e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32070</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.246668</td>\n",
       "      <td>0.213252</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>2.260000e-05</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>3.241458e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32071</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.246668</td>\n",
       "      <td>0.239830</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>3.084950e-04</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>1.780000e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32072 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             aa        ra        jc   pa  path_len      dc_A      dc_B  \\\n",
       "0      2.471649  0.531746  0.428571   96         1  0.002124  0.003186   \n",
       "1      2.976054  0.668651  0.466667  112         1  0.002124  0.003717   \n",
       "2      2.899858  0.628968  0.700000   72         1  0.002124  0.002390   \n",
       "3      2.471649  0.531746  0.600000   64         1  0.002124  0.002124   \n",
       "4      2.976054  0.668651  0.466667  112         1  0.002124  0.003717   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "32067  0.000000  0.000000  0.000000  510         3  0.002655  0.001328   \n",
       "32068  0.000000  0.000000  0.000000   30       999  0.002655  0.001593   \n",
       "32069  0.000000  0.000000  0.000000  310         3  0.002655  0.002390   \n",
       "32070  0.000000  0.000000  0.000000  140         3  0.002655  0.001062   \n",
       "32071  0.000000  0.000000  0.000000   60         4  0.002655  0.001062   \n",
       "\n",
       "           cc_A      cc_B    hits_A        hits_B    bet_cA        bet_cB  \n",
       "0      0.187879  0.223134  0.000003  5.710000e-05  0.000004  7.627580e-04  \n",
       "1      0.187879  0.209683  0.000003  1.070000e-05  0.000004  7.945610e-04  \n",
       "2      0.187879  0.187891  0.000003  3.200000e-06  0.000004  9.620000e-06  \n",
       "3      0.187879  0.181356  0.000003  2.090000e-06  0.000004  4.700000e-08  \n",
       "4      0.187879  0.208769  0.000003  1.830000e-05  0.000004  4.391450e-04  \n",
       "...         ...       ...       ...           ...       ...           ...  \n",
       "32067  0.246668  0.225652  0.000229  4.054780e-04  0.000371  4.349246e-03  \n",
       "32068  0.246668  0.173938  0.000229  5.740000e-07  0.000371  0.000000e+00  \n",
       "32069  0.246668  0.224344  0.000229  3.290000e-05  0.000371  6.463828e-03  \n",
       "32070  0.246668  0.213252  0.000229  2.260000e-05  0.000371  3.241458e-03  \n",
       "32071  0.246668  0.239830  0.000229  3.084950e-04  0.000371  1.780000e-05  \n",
       "\n",
       "[32072 rows x 13 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ra</th>\n",
       "      <th>jc</th>\n",
       "      <th>pa</th>\n",
       "      <th>path_len</th>\n",
       "      <th>dc_A</th>\n",
       "      <th>dc_B</th>\n",
       "      <th>cc_A</th>\n",
       "      <th>cc_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.187879</td>\n",
       "      <td>0.218136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.187879</td>\n",
       "      <td>0.203260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>496</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.008232</td>\n",
       "      <td>0.229441</td>\n",
       "      <td>0.256824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.242670</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.263182</td>\n",
       "      <td>0.206104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>391</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.246366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.177465</td>\n",
       "      <td>0.217868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.228538</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.214815</td>\n",
       "      <td>0.249028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1.766048</td>\n",
       "      <td>0.424368</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019649</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.280597</td>\n",
       "      <td>0.231677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.227797</td>\n",
       "      <td>0.169839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aa        ra        jc   pa  path_len      dc_A      dc_B  \\\n",
       "0     0.000000  0.000000  0.000000   56         3  0.002124  0.001859   \n",
       "1     0.000000  0.000000  0.000000   24         5  0.002124  0.000797   \n",
       "2     0.000000  0.000000  0.000000  496         3  0.004249  0.008232   \n",
       "3     1.242670  0.400000  0.080000   72         1  0.006373  0.000797   \n",
       "4     0.000000  0.000000  0.000000  391         4  0.004514  0.006107   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1995  0.000000  0.000000  0.000000    2         5  0.000266  0.000531   \n",
       "1996  0.000000  0.000000  0.000000    2       999  0.000531  0.000266   \n",
       "1997  0.000000  0.000000  0.000000  116         3  0.001062  0.007700   \n",
       "1998  1.766048  0.424368  0.053333  370         1  0.019649  0.001328   \n",
       "1999  0.000000  0.000000  0.000000   15         5  0.003983  0.000266   \n",
       "\n",
       "          cc_A      cc_B  \n",
       "0     0.187879  0.218136  \n",
       "1     0.187879  0.203260  \n",
       "2     0.229441  0.256824  \n",
       "3     0.263182  0.206104  \n",
       "4     0.247700  0.246366  \n",
       "...        ...       ...  \n",
       "1995  0.177465  0.217868  \n",
       "1996  0.228538  0.000266  \n",
       "1997  0.214815  0.249028  \n",
       "1998  0.280597  0.231677  \n",
       "1999  0.227797  0.169839  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[:,4:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [True if i < df.shape[0]/2 else False for i in range(df.shape[0])]\n",
    "x = df.iloc[:,4:13]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 16036, False: 16036})"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00      6324\n",
      "        True       1.00      1.00      1.00      6505\n",
      "\n",
      "    accuracy                           1.00     12829\n",
      "   macro avg       1.00      1.00      1.00     12829\n",
      "weighted avg       1.00      1.00      1.00     12829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#normal = StandardScaler()\n",
    "#x_train = normal.fit_transform(x_train)\n",
    "#x_test = normal.transform(x_test)\n",
    "\n",
    "LR = LogisticRegression(n_jobs = 4).fit(x_train, y_train)\n",
    "LRT = LR.predict(x_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, LRT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = LR.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 1261, False: 739})"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(LR.predict(test.iloc[:,4:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 13 features per sample; expecting 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-277-8abad45c2d44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1466\u001b[0m                                                 self.solver == 'liblinear')))\n\u001b[0;32m   1467\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0movr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1468\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1469\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1470\u001b[0m             \u001b[0mdecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m_predict_proba_lr\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mmulticlass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mhandled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnormalizing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mover\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \"\"\"\n\u001b[1;32m--> 321\u001b[1;33m         \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[0mexpit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 287\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 13 features per sample; expecting 9"
     ]
    }
   ],
   "source": [
    "results = LR.predict_proba(test.iloc[:,4:])\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': results[:,1]})\n",
    "output.to_csv('logReg.csv', header = True, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handmade gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "from sklearn.metrics import accuracy_score\n",
    "LR = LogisticRegression\n",
    "LR_param = {'penalty':['l1', 'l2', 'elasticnet'],\n",
    "            'C':[1.0,0.5,0.1,0.01], 'max_iter':[200],\n",
    "           'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "models = [('Logistic Regression',LR,LR_param)]\n",
    "\n",
    "result = []\n",
    "best = {}\n",
    "for name, m, params in models:\n",
    "    keys, values = zip(*params.items())\n",
    "    permutations = [dict(zip(keys, v)) for v in it.product(*values)]\n",
    "    \n",
    "    for p in permutations:\n",
    "        try:\n",
    "            mod = m(**p)\n",
    "            mod.fit(x_train, y_train);\n",
    "            y_pred = mod.predict(x_test)\n",
    "            Acc_scored = accuracy_score(y_test, y_pred)\n",
    "            cnt = collections.Counter(mod.predict(test.iloc[:,4:]))\n",
    "            best[str(p)] = (Acc_scored, cnt)\n",
    "            #print('Model: ',name, ' HyperParams: ',p,' Accuracy: ',Acc_scored)\n",
    "        except:\n",
    "            pass#print(p)\n",
    "\n",
    "    #best_params = max(best, key = lambda k:best[k][0])\n",
    "    #result.append((name, best_params, best[best_params][0], best[best_params][1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 1.0, 'max_iter': 200, 'solver': 'liblinear'} (1.0, Counter({False: 1229, True: 771}))\n",
      "{'penalty': 'l1', 'C': 1.0, 'max_iter': 200, 'solver': 'saga'} (0.7070699197131499, Counter({False: 1271, True: 729}))\n",
      "{'penalty': 'l1', 'C': 0.5, 'max_iter': 200, 'solver': 'liblinear'} (1.0, Counter({False: 1340, True: 660}))\n",
      "{'penalty': 'l1', 'C': 0.5, 'max_iter': 200, 'solver': 'saga'} (0.7071478681113104, Counter({False: 1271, True: 729}))\n",
      "{'penalty': 'l1', 'C': 0.1, 'max_iter': 200, 'solver': 'liblinear'} (1.0, Counter({False: 1347, True: 653}))\n",
      "{'penalty': 'l1', 'C': 0.1, 'max_iter': 200, 'solver': 'saga'} (0.7070699197131499, Counter({False: 1271, True: 729}))\n",
      "{'penalty': 'l1', 'C': 0.01, 'max_iter': 200, 'solver': 'liblinear'} (1.0, Counter({False: 1342, True: 658}))\n",
      "{'penalty': 'l1', 'C': 0.01, 'max_iter': 200, 'solver': 'saga'} (0.7061345389352249, Counter({False: 1269, True: 731}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'newton-cg'} (1.0, Counter({False: 1282, True: 718}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'lbfgs'} (1.0, Counter({False: 1282, True: 718}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'liblinear'} (1.0, Counter({False: 1290, True: 710}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'sag'} (0.7568789461376568, Counter({False: 1429, True: 571}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'saga'} (0.7069919713149895, Counter({False: 1271, True: 729}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'newton-cg'} (1.0, Counter({False: 1283, True: 717}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'lbfgs'} (1.0, Counter({False: 1283, True: 717}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'liblinear'} (1.0, Counter({False: 1282, True: 718}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'sag'} (0.7566451009431756, Counter({False: 1430, True: 570}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'saga'} (0.7070699197131499, Counter({False: 1271, True: 729}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'newton-cg'} (1.0, Counter({False: 1288, True: 712}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'lbfgs'} (1.0, Counter({False: 1289, True: 711}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'liblinear'} (1.0, Counter({False: 1303, True: 697}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'sag'} (0.7566451009431756, Counter({False: 1430, True: 570}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'saga'} (0.7070699197131499, Counter({False: 1271, True: 729}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'newton-cg'} (1.0, Counter({False: 1296, True: 704}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'lbfgs'} (1.0, Counter({False: 1296, True: 704}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'liblinear'} (1.0, Counter({False: 1359, True: 641}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'sag'} (0.7566451009431756, Counter({False: 1430, True: 570}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'saga'} (0.7070699197131499, Counter({False: 1271, True: 729}))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(k,v) for k,v in best.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's auc: 1\n",
      "[3]\tvalid_0's auc: 1\n",
      "[4]\tvalid_0's auc: 1\n",
      "[5]\tvalid_0's auc: 1\n",
      "[6]\tvalid_0's auc: 1\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "train_data = lgbm.Dataset(x_train, pd.Series(y_train))\n",
    "test_data = lgbm.Dataset(x_test, pd.Series(y_test))\n",
    "\n",
    "# define parameters\n",
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "#             'boosting_type': 'rf',\n",
    "        'nthread': 4,\n",
    "        'learning_rate': 0.02,  # 02,\n",
    "        'num_leaves': 15,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 1,\n",
    "        'early_stopping_round':5,\n",
    "        'max_depth':2,\n",
    "        'reg_alpha': 0.041545473,\n",
    "        'reg_lambda': 0.0735294,\n",
    "        'min_split_gain': 0.0222415,\n",
    "        'min_child_weight': 60,\n",
    "        'seed': 0,\n",
    "        'verbose': -1,\n",
    "        'metric': 'auc'\n",
    "}\n",
    "\n",
    "# train lightGBM model\n",
    "model = lgbm.train(parameters,\n",
    "                   train_data,\n",
    "                   valid_sets=test_data,\n",
    "                   num_boost_round=1000,\n",
    "                   early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48783832, 0.48783832, 0.48783832, ..., 0.48783832, 0.50783456,\n",
       "       0.48783832])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neg': 2000})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict= model.predict(test.iloc[:,7:])\n",
    "collections.Counter([\"pos\" if i>0.5 else \"neg\" for i in predict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      1.00      1.00      4041\n",
      "         pos       1.00      1.00      1.00      3977\n",
      "\n",
      "    accuracy                           1.00      8018\n",
      "   macro avg       1.00      1.00      1.00      8018\n",
      "weighted avg       1.00      1.00      1.00      8018\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "SVM = LinearSVC(max_iter=10000)\n",
    "#SVM_predict = SVM.predict(x_test)\n",
    "clf = CalibratedClassifierCV(SVM) \n",
    "clf.fit(x_train, y_train)\n",
    "clf_predict = clf.predict(x_test)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_test, clf_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67533204, 0.32466796],\n",
       "       [0.34029695, 0.65970305],\n",
       "       [0.35430718, 0.64569282],\n",
       "       ...,\n",
       "       [0.80227792, 0.19772208],\n",
       "       [0.67984221, 0.32015779],\n",
       "       [0.67347837, 0.32652163]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neg': 1465, 'pos': 535})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(clf.predict(test.iloc[:,4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neg': 4029, 'pos': 3989})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32588784, 0.11201567, 0.32562297, ..., 0.32601893, 0.65587601,\n",
       "       0.11203549])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = clf.predict_proba(test.iloc[:,4:])\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': predict})\n",
    "output.to_csv('lightGBM.csv', header = True, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
