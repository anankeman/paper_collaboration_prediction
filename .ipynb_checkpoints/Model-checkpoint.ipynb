{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test1_combined.csv\")\n",
    "df = pd.read_csv(\"train1_combined.csv\")\n",
    "dev = pd.read_csv(\"dev1_combined.csv\")\n",
    "#test.drop(test.columns[[13,14]], axis=1, inplace=True)\n",
    "#df.drop(df.columns[[13,14]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.iloc[:,4:-1]\n",
    "y_train = df.label\n",
    "x_dev = dev.iloc[:,4:-1]\n",
    "y_dev = dev.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27358, 11)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10110, 11)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5055"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev[dev.label ==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ra</th>\n",
       "      <th>jc</th>\n",
       "      <th>pa</th>\n",
       "      <th>dc_A</th>\n",
       "      <th>dc_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.508376</td>\n",
       "      <td>0.551129</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>88</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.003187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.049436</td>\n",
       "      <td>0.707973</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>104</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.003766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.984187</td>\n",
       "      <td>0.673785</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>72</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.002607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.027478</td>\n",
       "      <td>0.426129</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>56</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.002028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.060384</td>\n",
       "      <td>0.713467</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>112</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.004056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27353</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27354</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27355</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>207</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.002317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27356</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.003476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27357</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.002317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27358 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             aa        ra        jc   pa      dc_A      dc_B\n",
       "0      2.508376  0.551129  0.461538   88  0.002317  0.003187\n",
       "1      3.049436  0.707973  0.500000  104  0.002317  0.003766\n",
       "2      2.984187  0.673785  0.700000   72  0.002317  0.002607\n",
       "3      2.027478  0.426129  0.500000   56  0.002317  0.002028\n",
       "4      3.060384  0.713467  0.466667  112  0.002317  0.004056\n",
       "...         ...       ...       ...  ...       ...       ...\n",
       "27353  0.000000  0.000000  0.000000   51  0.002607  0.000290\n",
       "27354  0.000000  0.000000  0.000000   27  0.002607  0.000290\n",
       "27355  0.000000  0.000000  0.000000  207  0.002607  0.002317\n",
       "27356  0.000000  0.000000  0.000000   27  0.002607  0.003476\n",
       "27357  0.000000  0.000000  0.000000  144  0.002607  0.002317\n",
       "\n",
       "[27358 rows x 6 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,4:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ra</th>\n",
       "      <th>jc</th>\n",
       "      <th>pa</th>\n",
       "      <th>dc_A</th>\n",
       "      <th>dc_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.001448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>432</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.007822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.242670</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>57</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>0.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>391</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>0.006663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.006083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1.508374</td>\n",
       "      <td>0.404053</td>\n",
       "      <td>0.05</td>\n",
       "      <td>236</td>\n",
       "      <td>0.017092</td>\n",
       "      <td>0.001159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aa        ra    jc   pa      dc_A      dc_B\n",
       "0     0.000000  0.000000  0.00   40  0.002317  0.001448\n",
       "1     0.000000  0.000000  0.00   24  0.002317  0.000869\n",
       "2     0.000000  0.000000  0.00  432  0.004635  0.007822\n",
       "3     1.242670  0.400000  0.10   57  0.005504  0.000869\n",
       "4     0.000000  0.000000  0.00  391  0.004925  0.006663\n",
       "...        ...       ...   ...  ...       ...       ...\n",
       "1995  0.000000  0.000000  0.00    2  0.000290  0.000579\n",
       "1996  0.000000  0.000000  0.00    2  0.000579  0.000290\n",
       "1997  0.000000  0.000000  0.00   42  0.000579  0.006083\n",
       "1998  1.508374  0.404053  0.05  236  0.017092  0.001159\n",
       "1999  0.000000  0.000000  0.00   15  0.004345  0.000290\n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [True if i < df.shape[0]/2 else False for i in range(df.shape[0])]\n",
    "x = df.iloc[:,4:13]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 13679, False: 13679})"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83      5055\n",
      "           1       0.94      0.64      0.76      5055\n",
      "\n",
      "    accuracy                           0.80     10110\n",
      "   macro avg       0.83      0.80      0.80     10110\n",
      "weighted avg       0.83      0.80      0.80     10110\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1353: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#normal = StandardScaler()\n",
    "#x_train = normal.fit_transform(x_train)\n",
    "#x_test = normal.transform(x_test)\n",
    "#l1', 'C': 1.0, 'max_iter': 200, 'solver': 'liblinear'\n",
    "LR = LogisticRegression(n_jobs = 4, penalty = 'l1', solver = 'liblinear').fit(df.iloc[:,4:-1], df.label)\n",
    "LRT = LR.predict(dev.iloc[:,4:-1])\n",
    "\n",
    "print(metrics.classification_report(dev.label, LRT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = LR.predict_proba(dev.iloc[:,4:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8090631344038525"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(dev.label, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1406, 1: 594})"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(LR.predict(test.iloc[:,4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06686987, 0.06587346, 0.09605604, ..., 0.0669954 , 1.        ,\n",
       "       0.06531907])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = LR.predict_proba(test.iloc[:,4:])\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': results[:,1]})\n",
    "output.to_csv('logReg.csv', header = True, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handmade gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "from sklearn.metrics import accuracy_score\n",
    "LR = LogisticRegression\n",
    "LR_param = {'penalty':['l1', 'l2', 'elasticnet'],\n",
    "            'C':[1.0,0.5,0.1,0.01], 'max_iter':[200],\n",
    "           'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "models = [('Logistic Regression',LR,LR_param)]\n",
    "\n",
    "result = []\n",
    "best = {}\n",
    "for name, m, params in models:\n",
    "    keys, values = zip(*params.items())\n",
    "    permutations = [dict(zip(keys, v)) for v in it.product(*values)]\n",
    "    \n",
    "    for p in permutations:\n",
    "        try:\n",
    "            mod = m(**p)\n",
    "            mod.fit(x_train, y_train);\n",
    "            y_pred = mod.predict(x_dev)\n",
    "            Acc_scored = accuracy_score(y_dev, y_pred)\n",
    "            cnt = collections.Counter(mod.predict(test.iloc[:,4:]))\n",
    "            best[str(p)] = (Acc_scored, cnt)\n",
    "            #print('Model: ',name, ' HyperParams: ',p,' Accuracy: ',Acc_scored)\n",
    "        except:\n",
    "            pass#print(p)\n",
    "\n",
    "    #best_params = max(best, key = lambda k:best[k][0])\n",
    "    #result.append((name, best_params, best[best_params][0], best[best_params][1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 1.0, 'max_iter': 200, 'solver': 'liblinear'} (0.7816666666666666, Counter({0: 1439, 1: 561}))\n",
      "{'penalty': 'l1', 'C': 1.0, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l1', 'C': 0.5, 'max_iter': 200, 'solver': 'liblinear'} (0.7816666666666666, Counter({0: 1439, 1: 561}))\n",
      "{'penalty': 'l1', 'C': 0.5, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l1', 'C': 0.1, 'max_iter': 200, 'solver': 'liblinear'} (0.7815833333333333, Counter({0: 1439, 1: 561}))\n",
      "{'penalty': 'l1', 'C': 0.1, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l1', 'C': 0.01, 'max_iter': 200, 'solver': 'liblinear'} (0.7808333333333334, Counter({0: 1440, 1: 560}))\n",
      "{'penalty': 'l1', 'C': 0.01, 'max_iter': 200, 'solver': 'saga'} (0.51925, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'newton-cg'} (0.7818333333333334, Counter({0: 1439, 1: 561}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'lbfgs'} (0.7818333333333334, Counter({0: 1439, 1: 561}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'liblinear'} (0.7783333333333333, Counter({0: 1448, 1: 552}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'sag'} (0.566, Counter({1: 1622, 0: 378}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'newton-cg'} (0.7818333333333334, Counter({0: 1438, 1: 562}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'lbfgs'} (0.7818333333333334, Counter({0: 1438, 1: 562}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'liblinear'} (0.7779166666666667, Counter({0: 1448, 1: 552}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'sag'} (0.566, Counter({1: 1622, 0: 378}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'newton-cg'} (0.7811666666666667, Counter({0: 1440, 1: 560}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'lbfgs'} (0.7811666666666667, Counter({0: 1440, 1: 560}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'liblinear'} (0.7754166666666666, Counter({0: 1460, 1: 540}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'sag'} (0.566, Counter({1: 1622, 0: 378}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'newton-cg'} (0.7589166666666667, Counter({0: 1527, 1: 473}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'lbfgs'} (0.759, Counter({0: 1527, 1: 473}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'liblinear'} (0.75775, Counter({0: 1529, 1: 471}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'sag'} (0.566, Counter({1: 1622, 0: 378}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(k,v) for k,v in best.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12810, number of negative: 12810\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1018\n",
      "[LightGBM] [Info] Number of data points in the train set: 25620, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's auc: 0.78175\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's auc: 0.78175\n",
      "[3]\tvalid_0's auc: 0.822314\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's auc: 0.822314\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's auc: 0.82227\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's auc: 0.822207\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's auc: 0.822314\n",
      "[8]\tvalid_0's auc: 0.824169\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's auc: 0.824169\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's auc: 0.824169\n",
      "[11]\tvalid_0's auc: 0.824643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's auc: 0.824643\n",
      "[13]\tvalid_0's auc: 0.824468\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's auc: 0.824468\n",
      "[15]\tvalid_0's auc: 0.824476\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's auc: 0.824476\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's auc: 0.824476\n",
      "[18]\tvalid_0's auc: 0.825407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's auc: 0.825407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's auc: 0.825407\n",
      "[21]\tvalid_0's auc: 0.825347\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's auc: 0.825347\n",
      "[23]\tvalid_0's auc: 0.824467\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's auc: 0.824467\n",
      "[25]\tvalid_0's auc: 0.822773\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's auc: 0.822773\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's auc: 0.822773\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's auc: 0.822773\n",
      "[29]\tvalid_0's auc: 0.823589\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's auc: 0.823589\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's auc: 0.823589\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's auc: 0.823589\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's auc: 0.823589\n",
      "[34]\tvalid_0's auc: 0.824014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's auc: 0.824014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's auc: 0.824014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's auc: 0.824014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's auc: 0.824014\n",
      "[39]\tvalid_0's auc: 0.824025\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's auc: 0.824025\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's auc: 0.824025\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's auc: 0.824025\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's auc: 0.824025\n",
      "[44]\tvalid_0's auc: 0.822894\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's auc: 0.822894\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's auc: 0.822894\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's auc: 0.822894\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's auc: 0.822684\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's auc: 0.822511\n",
      "[50]\tvalid_0's auc: 0.821173\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's auc: 0.821173\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[52]\tvalid_0's auc: 0.824713\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\tvalid_0's auc: 0.824651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\tvalid_0's auc: 0.823919\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's auc: 0.823919\n",
      "[56]\tvalid_0's auc: 0.822104\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[57]\tvalid_0's auc: 0.822059\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[58]\tvalid_0's auc: 0.822057\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.825407\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "train_data = lgbm.Dataset(x_train, pd.Series(y_train))\n",
    "test_data = lgbm.Dataset(x_dev, pd.Series(y_dev))\n",
    "\n",
    "# define parameters\n",
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'num_threads' : 2,\n",
    "    'seed' : 76\n",
    "}\n",
    "\n",
    "# train lightGBM model\n",
    "model = lgbm.train(parameters,\n",
    "                   train_data,\n",
    "                   valid_sets=test_data,\n",
    "                   num_boost_round=1000,\n",
    "                   early_stopping_rounds=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49348902, 0.49348902, 0.49348902, ..., 0.49348902, 0.49348902,\n",
       "       0.49348902])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neg': 1439, 'pos': 561})"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict= model.predict(test.iloc[:,4:])\n",
    "collections.Counter([\"pos\" if i>0.5 else \"neg\" for i in predict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# define min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_dev = scaler.fit_transform(x_dev)\n",
    "test = test.iloc[:,4:]\n",
    "test = scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1354199 , 0.1771918 , 0.49846154, 0.00669488, 0.0619469 ,\n",
       "        0.08849559],\n",
       "       [0.16463012, 0.22761792, 0.54      , 0.00792613, 0.0619469 ,\n",
       "        0.1061947 ],\n",
       "       [0.16110755, 0.21662624, 0.756     , 0.00546364, 0.0619469 ,\n",
       "        0.07079646],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , 0.01585225, 0.07079646,\n",
       "        0.0619469 ],\n",
       "       [0.        , 0.        , 0.        , 0.00200077, 0.07079646,\n",
       "        0.09734515],\n",
       "       [0.        , 0.        , 0.        , 0.01100423, 0.07079646,\n",
       "        0.0619469 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: linear c: 0.001\n",
      "0.7959190545933407\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78      5055\n",
      "           1       0.84      0.63      0.72      5055\n",
      "\n",
      "    accuracy                           0.76     10110\n",
      "   macro avg       0.77      0.76      0.75     10110\n",
      "weighted avg       0.77      0.76      0.75     10110\n",
      "\n",
      "kernel: linear c: 0.01\n",
      "0.8054568294751795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.93      0.80      5055\n",
      "           1       0.89      0.62      0.73      5055\n",
      "\n",
      "    accuracy                           0.77     10110\n",
      "   macro avg       0.80      0.77      0.77     10110\n",
      "weighted avg       0.80      0.77      0.77     10110\n",
      "\n",
      "kernel: linear c: 0.1\n",
      "0.8037495169358617\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.99      0.82      5055\n",
      "           1       0.98      0.57      0.72      5055\n",
      "\n",
      "    accuracy                           0.78     10110\n",
      "   macro avg       0.84      0.78      0.77     10110\n",
      "weighted avg       0.84      0.78      0.77     10110\n",
      "\n",
      "kernel: linear c: 0.5\n",
      "0.7970687423504653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.99      0.81      5055\n",
      "           1       0.98      0.55      0.71      5055\n",
      "\n",
      "    accuracy                           0.77     10110\n",
      "   macro avg       0.83      0.77      0.76     10110\n",
      "weighted avg       0.83      0.77      0.76     10110\n",
      "\n",
      "kernel: linear c: 0.8\n",
      "0.7967750002201306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.99      0.81      5055\n",
      "           1       0.98      0.54      0.69      5055\n",
      "\n",
      "    accuracy                           0.76     10110\n",
      "   macro avg       0.83      0.76      0.75     10110\n",
      "weighted avg       0.83      0.76      0.75     10110\n",
      "\n",
      "kernel: linear c: 1.0\n",
      "0.7966280900206532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.99      0.81      5055\n",
      "           1       0.98      0.55      0.70      5055\n",
      "\n",
      "    accuracy                           0.77     10110\n",
      "   macro avg       0.83      0.77      0.76     10110\n",
      "weighted avg       0.83      0.77      0.76     10110\n",
      "\n",
      "kernel: poly c: 0.001\n",
      "0.783477005168664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.98      0.72      5055\n",
      "           1       0.93      0.27      0.41      5055\n",
      "\n",
      "    accuracy                           0.62     10110\n",
      "   macro avg       0.75      0.62      0.57     10110\n",
      "weighted avg       0.75      0.62      0.57     10110\n",
      "\n",
      "kernel: poly c: 0.01\n",
      "0.7695681626734996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.72      5055\n",
      "           1       0.98      0.24      0.39      5055\n",
      "\n",
      "    accuracy                           0.62     10110\n",
      "   macro avg       0.78      0.62      0.56     10110\n",
      "weighted avg       0.78      0.62      0.56     10110\n",
      "\n",
      "kernel: poly c: 0.1\n",
      "0.8388596849101038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.72      5055\n",
      "           1       0.99      0.24      0.39      5055\n",
      "\n",
      "    accuracy                           0.62     10110\n",
      "   macro avg       0.78      0.62      0.56     10110\n",
      "weighted avg       0.78      0.62      0.56     10110\n",
      "\n",
      "kernel: poly c: 0.5\n",
      "0.8596468911215012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.72      5055\n",
      "           1       0.99      0.23      0.37      5055\n",
      "\n",
      "    accuracy                           0.61     10110\n",
      "   macro avg       0.78      0.61      0.55     10110\n",
      "weighted avg       0.78      0.61      0.55     10110\n",
      "\n",
      "kernel: poly c: 0.8\n",
      "0.8636840256681939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.72      5055\n",
      "           1       0.99      0.22      0.37      5055\n",
      "\n",
      "    accuracy                           0.61     10110\n",
      "   macro avg       0.78      0.61      0.54     10110\n",
      "weighted avg       0.78      0.61      0.54     10110\n",
      "\n",
      "kernel: poly c: 1.0\n",
      "0.8737984446068519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.72      5055\n",
      "           1       0.99      0.22      0.36      5055\n",
      "\n",
      "    accuracy                           0.61     10110\n",
      "   macro avg       0.78      0.61      0.54     10110\n",
      "weighted avg       0.78      0.61      0.54     10110\n",
      "\n",
      "kernel: rbf c: 0.001\n",
      "0.800719895198318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77      5055\n",
      "           1       0.82      0.63      0.71      5055\n",
      "\n",
      "    accuracy                           0.75     10110\n",
      "   macro avg       0.76      0.75      0.74     10110\n",
      "weighted avg       0.76      0.75      0.74     10110\n",
      "\n",
      "kernel: rbf c: 0.01\n",
      "0.8294096491511279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.81      5055\n",
      "           1       0.89      0.65      0.75      5055\n",
      "\n",
      "    accuracy                           0.78     10110\n",
      "   macro avg       0.80      0.78      0.78     10110\n",
      "weighted avg       0.80      0.78      0.78     10110\n",
      "\n",
      "kernel: rbf c: 0.1\n",
      "0.8831475921148279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.95      0.83      5055\n",
      "           1       0.93      0.66      0.77      5055\n",
      "\n",
      "    accuracy                           0.80     10110\n",
      "   macro avg       0.83      0.80      0.80     10110\n",
      "weighted avg       0.83      0.80      0.80     10110\n",
      "\n",
      "kernel: rbf c: 0.5\n",
      "0.8955103162932765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.83      5055\n",
      "           1       0.94      0.66      0.77      5055\n",
      "\n",
      "    accuracy                           0.81     10110\n",
      "   macro avg       0.84      0.81      0.80     10110\n",
      "weighted avg       0.84      0.81      0.80     10110\n",
      "\n",
      "kernel: rbf c: 0.8\n",
      "0.8949632969090744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.83      5055\n",
      "           1       0.94      0.66      0.77      5055\n",
      "\n",
      "    accuracy                           0.81     10110\n",
      "   macro avg       0.84      0.81      0.80     10110\n",
      "weighted avg       0.84      0.81      0.80     10110\n",
      "\n",
      "kernel: rbf c: 1.0\n",
      "0.8947967021517022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.83      5055\n",
      "           1       0.95      0.66      0.78      5055\n",
      "\n",
      "    accuracy                           0.81     10110\n",
      "   macro avg       0.84      0.81      0.81     10110\n",
      "weighted avg       0.84      0.81      0.81     10110\n",
      "\n",
      "kernel: sigmoid c: 0.001\n",
      "0.8027090530377519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77      5055\n",
      "           1       0.79      0.68      0.73      5055\n",
      "\n",
      "    accuracy                           0.75     10110\n",
      "   macro avg       0.75      0.75      0.75     10110\n",
      "weighted avg       0.75      0.75      0.75     10110\n",
      "\n",
      "kernel: sigmoid c: 0.01\n",
      "0.7634751854232522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.69      5055\n",
      "           1       0.69      0.72      0.70      5055\n",
      "\n",
      "    accuracy                           0.70     10110\n",
      "   macro avg       0.70      0.70      0.70     10110\n",
      "weighted avg       0.70      0.70      0.70     10110\n",
      "\n",
      "kernel: sigmoid c: 0.1\n",
      "0.757197572498755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69      5055\n",
      "           1       0.69      0.71      0.70      5055\n",
      "\n",
      "    accuracy                           0.69     10110\n",
      "   macro avg       0.69      0.69      0.69     10110\n",
      "weighted avg       0.69      0.69      0.69     10110\n",
      "\n",
      "kernel: sigmoid c: 0.5\n",
      "0.7564688133792379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69      5055\n",
      "           1       0.69      0.71      0.70      5055\n",
      "\n",
      "    accuracy                           0.69     10110\n",
      "   macro avg       0.69      0.69      0.69     10110\n",
      "weighted avg       0.69      0.69      0.69     10110\n",
      "\n",
      "kernel: sigmoid c: 0.8\n",
      "0.7564007979485794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69      5055\n",
      "           1       0.69      0.71      0.70      5055\n",
      "\n",
      "    accuracy                           0.69     10110\n",
      "   macro avg       0.69      0.69      0.69     10110\n",
      "weighted avg       0.69      0.69      0.69     10110\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: sigmoid c: 1.0\n",
      "0.7563713689475121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69      5055\n",
      "           1       0.69      0.71      0.70      5055\n",
      "\n",
      "    accuracy                           0.69     10110\n",
      "   macro avg       0.69      0.69      0.69     10110\n",
      "weighted avg       0.69      0.69      0.69     10110\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Precomputed matrix must be a square matrix. Input is a 21886x6 matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-918660258c5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m#SVM_predict = SVM.predict(x_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCalibratedClassifierCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSVM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mclf_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\calibration.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    176\u001b[0m                                        sample_weight=sample_weight[train])\n\u001b[0;32m    177\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                     \u001b[0mthis_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                 calibrated_classifier = _CalibratedClassifier(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"precomputed\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             raise ValueError(\"Precomputed matrix must be a square matrix.\"\n\u001b[0m\u001b[0;32m    180\u001b[0m                              \u001b[1;34m\" Input is a {}x{} matrix.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m                              .format(X.shape[0], X.shape[1]))\n",
      "\u001b[1;31mValueError\u001b[0m: Precomputed matrix must be a square matrix. Input is a 21886x6 matrix."
     ]
    }
   ],
   "source": [
    "C = [0.001, 0.01, 0.1, 0.5, 0.8, 1.0]\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid'] # cannot use precomputed as square matrix as input required\n",
    "for kernel in kernels:\n",
    "    for c in C:\n",
    "        SVM = SVC(kernel=kernel, C=c)\n",
    "        #SVM_predict = SVM.predict(x_test)\n",
    "        clf = CalibratedClassifierCV(SVM) \n",
    "        clf.fit(x_train, y_train)\n",
    "        clf_predict = clf.predict(x_dev)\n",
    "\n",
    "        probs = clf.predict_proba(x_dev)\n",
    "        print(\"kernel:\", kernel, 'c:', c)\n",
    "        print(metrics.roc_auc_score(y_dev, probs[:, 1]))\n",
    "        print(metrics.classification_report(y_dev, clf_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.34791090e-06, 9.99997652e-01],\n",
       "       [3.46543691e-07, 9.99999653e-01],\n",
       "       [4.10257686e-09, 9.99999996e-01],\n",
       "       ...,\n",
       "       [8.67132316e-01, 1.32867684e-01],\n",
       "       [8.66075798e-01, 1.33924202e-01],\n",
       "       [8.65616779e-01, 1.34383221e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8033017030273324"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_dev, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1482, 1: 518})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(clf.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 5476, True: 5468})"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13763453, 0.13498498, 0.19731051, ..., 0.14553475, 0.97989787,\n",
       "       0.13750816])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = clf.predict_proba(test)\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': predict})\n",
    "output.to_csv('lightGBM.csv', header = True, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90      5055\n",
      "           1       0.94      0.84      0.89      5055\n",
      "\n",
      "    accuracy                           0.89     10110\n",
      "   macro avg       0.90      0.89      0.89     10110\n",
      "weighted avg       0.90      0.89      0.89     10110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(max_depth=12, random_state=0, oob_score=True, bootstrap=True).fit(x_train, y_train) # max_depth 6 is optimal depth.\n",
    "rfc_pred = rfc.predict(x_dev)\n",
    "\n",
    "print(metrics.classification_report(y_dev, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9922874479128592\n"
     ]
    }
   ],
   "source": [
    "print('Score: ', rfc.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9812486292857665\n"
     ]
    }
   ],
   "source": [
    "print(rfc.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = rfc.predict_proba(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       ...,\n",
       "       [0.2225993 , 0.7774007 ],\n",
       "       [0.98262554, 0.01737446],\n",
       "       [0.94112617, 0.05887383]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9645049852219063"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_dev, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 843, 1: 1157})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(rfc.predict(test.iloc[:,4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10305407, 0.06810847, 0.63921827, ..., 0.10767577, 1.        ,\n",
       "       0.29842463])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = rfc.predict_proba(test.iloc[:,4:])\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': results[:,1]})\n",
    "output.to_csv('randomForest_6feat.csv', header = True, index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
