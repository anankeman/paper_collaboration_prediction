{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test1_combined.csv\")\n",
    "df = pd.read_csv(\"train1_combined.csv\")\n",
    "dev = pd.read_csv(\"dev1_combined.csv\")\n",
    "#test.drop(test.columns[[13,14]], axis=1, inplace=True)\n",
    "#df.drop(df.columns[[13,14]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.iloc[:,4:-1]\n",
    "y_train = df.label\n",
    "x_dev = dev.iloc[:,4:-1]\n",
    "y_dev = dev.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27358, 11)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10110, 11)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5055"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev[dev.label ==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ra</th>\n",
       "      <th>jc</th>\n",
       "      <th>pa</th>\n",
       "      <th>dc_A</th>\n",
       "      <th>dc_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.508376</td>\n",
       "      <td>0.551129</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>88</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.003187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.049436</td>\n",
       "      <td>0.707973</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>104</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.003766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.984187</td>\n",
       "      <td>0.673785</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>72</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.002607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.027478</td>\n",
       "      <td>0.426129</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>56</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.002028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.060384</td>\n",
       "      <td>0.713467</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>112</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.004056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27353</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27354</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27355</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>207</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.002317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27356</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.003476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27357</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.002317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27358 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             aa        ra        jc   pa      dc_A      dc_B\n",
       "0      2.508376  0.551129  0.461538   88  0.002317  0.003187\n",
       "1      3.049436  0.707973  0.500000  104  0.002317  0.003766\n",
       "2      2.984187  0.673785  0.700000   72  0.002317  0.002607\n",
       "3      2.027478  0.426129  0.500000   56  0.002317  0.002028\n",
       "4      3.060384  0.713467  0.466667  112  0.002317  0.004056\n",
       "...         ...       ...       ...  ...       ...       ...\n",
       "27353  0.000000  0.000000  0.000000   51  0.002607  0.000290\n",
       "27354  0.000000  0.000000  0.000000   27  0.002607  0.000290\n",
       "27355  0.000000  0.000000  0.000000  207  0.002607  0.002317\n",
       "27356  0.000000  0.000000  0.000000   27  0.002607  0.003476\n",
       "27357  0.000000  0.000000  0.000000  144  0.002607  0.002317\n",
       "\n",
       "[27358 rows x 6 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,4:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ra</th>\n",
       "      <th>jc</th>\n",
       "      <th>pa</th>\n",
       "      <th>dc_A</th>\n",
       "      <th>dc_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.001448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>432</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.007822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.242670</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>57</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>0.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>391</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>0.006663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.006083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1.508374</td>\n",
       "      <td>0.404053</td>\n",
       "      <td>0.05</td>\n",
       "      <td>236</td>\n",
       "      <td>0.017092</td>\n",
       "      <td>0.001159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aa        ra    jc   pa      dc_A      dc_B\n",
       "0     0.000000  0.000000  0.00   40  0.002317  0.001448\n",
       "1     0.000000  0.000000  0.00   24  0.002317  0.000869\n",
       "2     0.000000  0.000000  0.00  432  0.004635  0.007822\n",
       "3     1.242670  0.400000  0.10   57  0.005504  0.000869\n",
       "4     0.000000  0.000000  0.00  391  0.004925  0.006663\n",
       "...        ...       ...   ...  ...       ...       ...\n",
       "1995  0.000000  0.000000  0.00    2  0.000290  0.000579\n",
       "1996  0.000000  0.000000  0.00    2  0.000579  0.000290\n",
       "1997  0.000000  0.000000  0.00   42  0.000579  0.006083\n",
       "1998  1.508374  0.404053  0.05  236  0.017092  0.001159\n",
       "1999  0.000000  0.000000  0.00   15  0.004345  0.000290\n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [True if i < df.shape[0]/2 else False for i in range(df.shape[0])]\n",
    "x = df.iloc[:,4:13]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 13679, False: 13679})"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83      5055\n",
      "           1       0.94      0.64      0.76      5055\n",
      "\n",
      "    accuracy                           0.80     10110\n",
      "   macro avg       0.83      0.80      0.80     10110\n",
      "weighted avg       0.83      0.80      0.80     10110\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1353: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#normal = StandardScaler()\n",
    "#x_train = normal.fit_transform(x_train)\n",
    "#x_test = normal.transform(x_test)\n",
    "#l1', 'C': 1.0, 'max_iter': 200, 'solver': 'liblinear'\n",
    "LR = LogisticRegression(n_jobs = 4, penalty = 'l1', solver = 'liblinear').fit(df.iloc[:,4:-1], df.label)\n",
    "LRT = LR.predict(dev.iloc[:,4:-1])\n",
    "\n",
    "print(metrics.classification_report(dev.label, LRT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = LR.predict_proba(dev.iloc[:,4:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8090631344038525"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(dev.label, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1406, 1: 594})"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(LR.predict(test.iloc[:,4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06686987, 0.06587346, 0.09605604, ..., 0.0669954 , 1.        ,\n",
       "       0.06531907])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = LR.predict_proba(test.iloc[:,4:])\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': results[:,1]})\n",
    "output.to_csv('logReg.csv', header = True, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handmade gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "from sklearn.metrics import accuracy_score\n",
    "LR = LogisticRegression\n",
    "LR_param = {'penalty':['l1', 'l2', 'elasticnet'],\n",
    "            'C':[1.0,0.5,0.1,0.01], 'max_iter':[200],\n",
    "           'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "models = [('Logistic Regression',LR,LR_param)]\n",
    "\n",
    "result = []\n",
    "best = {}\n",
    "for name, m, params in models:\n",
    "    keys, values = zip(*params.items())\n",
    "    permutations = [dict(zip(keys, v)) for v in it.product(*values)]\n",
    "    \n",
    "    for p in permutations:\n",
    "        try:\n",
    "            mod = m(**p)\n",
    "            mod.fit(x_train, y_train);\n",
    "            y_pred = mod.predict(x_dev)\n",
    "            Acc_scored = accuracy_score(y_dev, y_pred)\n",
    "            cnt = collections.Counter(mod.predict(test.iloc[:,4:]))\n",
    "            best[str(p)] = (Acc_scored, cnt)\n",
    "            #print('Model: ',name, ' HyperParams: ',p,' Accuracy: ',Acc_scored)\n",
    "        except:\n",
    "            pass#print(p)\n",
    "\n",
    "    #best_params = max(best, key = lambda k:best[k][0])\n",
    "    #result.append((name, best_params, best[best_params][0], best[best_params][1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 1.0, 'max_iter': 200, 'solver': 'liblinear'} (0.7816666666666666, Counter({0: 1439, 1: 561}))\n",
      "{'penalty': 'l1', 'C': 1.0, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l1', 'C': 0.5, 'max_iter': 200, 'solver': 'liblinear'} (0.7816666666666666, Counter({0: 1439, 1: 561}))\n",
      "{'penalty': 'l1', 'C': 0.5, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l1', 'C': 0.1, 'max_iter': 200, 'solver': 'liblinear'} (0.7815833333333333, Counter({0: 1439, 1: 561}))\n",
      "{'penalty': 'l1', 'C': 0.1, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l1', 'C': 0.01, 'max_iter': 200, 'solver': 'liblinear'} (0.7808333333333334, Counter({0: 1440, 1: 560}))\n",
      "{'penalty': 'l1', 'C': 0.01, 'max_iter': 200, 'solver': 'saga'} (0.51925, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'newton-cg'} (0.7818333333333334, Counter({0: 1439, 1: 561}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'lbfgs'} (0.7818333333333334, Counter({0: 1439, 1: 561}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'liblinear'} (0.7783333333333333, Counter({0: 1448, 1: 552}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'sag'} (0.566, Counter({1: 1622, 0: 378}))\n",
      "{'penalty': 'l2', 'C': 1.0, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'newton-cg'} (0.7818333333333334, Counter({0: 1438, 1: 562}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'lbfgs'} (0.7818333333333334, Counter({0: 1438, 1: 562}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'liblinear'} (0.7779166666666667, Counter({0: 1448, 1: 552}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'sag'} (0.566, Counter({1: 1622, 0: 378}))\n",
      "{'penalty': 'l2', 'C': 0.5, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'newton-cg'} (0.7811666666666667, Counter({0: 1440, 1: 560}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'lbfgs'} (0.7811666666666667, Counter({0: 1440, 1: 560}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'liblinear'} (0.7754166666666666, Counter({0: 1460, 1: 540}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'sag'} (0.566, Counter({1: 1622, 0: 378}))\n",
      "{'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'newton-cg'} (0.7589166666666667, Counter({0: 1527, 1: 473}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'lbfgs'} (0.759, Counter({0: 1527, 1: 473}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'liblinear'} (0.75775, Counter({0: 1529, 1: 471}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'sag'} (0.566, Counter({1: 1622, 0: 378}))\n",
      "{'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'saga'} (0.5193333333333333, Counter({1: 1810, 0: 190}))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(k,v) for k,v in best.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12810, number of negative: 12810\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1018\n",
      "[LightGBM] [Info] Number of data points in the train set: 25620, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's auc: 0.78175\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's auc: 0.78175\n",
      "[3]\tvalid_0's auc: 0.822314\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's auc: 0.822314\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's auc: 0.82227\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's auc: 0.822207\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's auc: 0.822314\n",
      "[8]\tvalid_0's auc: 0.824169\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's auc: 0.824169\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's auc: 0.824169\n",
      "[11]\tvalid_0's auc: 0.824643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's auc: 0.824643\n",
      "[13]\tvalid_0's auc: 0.824468\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's auc: 0.824468\n",
      "[15]\tvalid_0's auc: 0.824476\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's auc: 0.824476\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's auc: 0.824476\n",
      "[18]\tvalid_0's auc: 0.825407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's auc: 0.825407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's auc: 0.825407\n",
      "[21]\tvalid_0's auc: 0.825347\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's auc: 0.825347\n",
      "[23]\tvalid_0's auc: 0.824467\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's auc: 0.824467\n",
      "[25]\tvalid_0's auc: 0.822773\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's auc: 0.822773\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's auc: 0.822773\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's auc: 0.822773\n",
      "[29]\tvalid_0's auc: 0.823589\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's auc: 0.823589\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's auc: 0.823589\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's auc: 0.823589\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's auc: 0.823589\n",
      "[34]\tvalid_0's auc: 0.824014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's auc: 0.824014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's auc: 0.824014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's auc: 0.824014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's auc: 0.824014\n",
      "[39]\tvalid_0's auc: 0.824025\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's auc: 0.824025\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's auc: 0.824025\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's auc: 0.824025\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's auc: 0.824025\n",
      "[44]\tvalid_0's auc: 0.822894\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's auc: 0.822894\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's auc: 0.822894\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's auc: 0.822894\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's auc: 0.822684\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's auc: 0.822511\n",
      "[50]\tvalid_0's auc: 0.821173\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's auc: 0.821173\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[52]\tvalid_0's auc: 0.824713\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\tvalid_0's auc: 0.824651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\tvalid_0's auc: 0.823919\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's auc: 0.823919\n",
      "[56]\tvalid_0's auc: 0.822104\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[57]\tvalid_0's auc: 0.822059\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[58]\tvalid_0's auc: 0.822057\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.825407\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "train_data = lgbm.Dataset(x_train, pd.Series(y_train))\n",
    "test_data = lgbm.Dataset(x_dev, pd.Series(y_dev))\n",
    "\n",
    "# define parameters\n",
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'num_threads' : 2,\n",
    "    'seed' : 76\n",
    "}\n",
    "\n",
    "# train lightGBM model\n",
    "model = lgbm.train(parameters,\n",
    "                   train_data,\n",
    "                   valid_sets=test_data,\n",
    "                   num_boost_round=1000,\n",
    "                   early_stopping_rounds=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49348902, 0.49348902, 0.49348902, ..., 0.49348902, 0.49348902,\n",
       "       0.49348902])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neg': 1439, 'pos': 561})"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict= model.predict(test.iloc[:,4:])\n",
    "collections.Counter([\"pos\" if i>0.5 else \"neg\" for i in predict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.99      0.79      5055\n",
      "           1       0.98      0.48      0.65      5055\n",
      "\n",
      "    accuracy                           0.74     10110\n",
      "   macro avg       0.82      0.74      0.72     10110\n",
      "weighted avg       0.82      0.74      0.72     10110\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melissa Speer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "SVM = LinearSVC(max_iter=10000)\n",
    "#SVM_predict = SVM.predict(x_test)\n",
    "clf = CalibratedClassifierCV(SVM) \n",
    "clf.fit(x_train, y_train)\n",
    "clf_predict = clf.predict(x_dev)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_dev, clf_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01230938, 0.98769062],\n",
       "       [0.00379426, 0.99620574],\n",
       "       [0.00392456, 0.99607544],\n",
       "       ...,\n",
       "       [0.82891899, 0.17108101],\n",
       "       [0.82907605, 0.17092395],\n",
       "       [0.82921991, 0.17078009]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8188207267045682"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_dev, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1611, 1: 389})"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(clf.predict(test.iloc[:,4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 5476, True: 5468})"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17055957, 0.17083283, 0.164178  , ..., 0.17049082, 0.8812935 ,\n",
       "       0.17092608])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = clf.predict_proba(test.iloc[:,4:])\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': predict})\n",
    "output.to_csv('lightGBM.csv', header = True, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90      5055\n",
      "           1       0.94      0.84      0.89      5055\n",
      "\n",
      "    accuracy                           0.89     10110\n",
      "   macro avg       0.90      0.89      0.89     10110\n",
      "weighted avg       0.90      0.89      0.89     10110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(max_depth=12, random_state=0, oob_score=True, bootstrap=True).fit(x_train, y_train) # max_depth 6 is optimal depth.\n",
    "rfc_pred = rfc.predict(x_dev)\n",
    "\n",
    "print(metrics.classification_report(y_dev, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9922874479128592\n"
     ]
    }
   ],
   "source": [
    "print('Score: ', rfc.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9812486292857665\n"
     ]
    }
   ],
   "source": [
    "print(rfc.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = rfc.predict_proba(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       ...,\n",
       "       [0.2225993 , 0.7774007 ],\n",
       "       [0.98262554, 0.01737446],\n",
       "       [0.94112617, 0.05887383]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9645049852219063"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_dev, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 843, 1: 1157})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(rfc.predict(test.iloc[:,4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10305407, 0.06810847, 0.63921827, ..., 0.10767577, 1.        ,\n",
       "       0.29842463])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = rfc.predict_proba(test.iloc[:,4:])\n",
    "results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': [i for i in range(1,2001)], 'Predicted': results[:,1]})\n",
    "output.to_csv('randomForest_6feat.csv', header = True, index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
